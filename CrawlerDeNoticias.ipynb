{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8849ed6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Crawler Noticias do G1\n",
    "\n",
    "Capturando noticias do portal G1 da Globo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f31df",
   "metadata": {},
   "source": [
    "Estudo projeto de construção de um bot crawler para extrair e indexar noticias de sites.\n",
    "\n",
    "É recomendavel baixar uma única vez o html do site para reduzir a necessidade de acessar o site várias vezes para cada processamento reduzindo tempo e custo computacionais para máquina local e servidor.\n",
    "\n",
    "Usamos módulo _Requests_ para baixar o html da página a ser processada e com módulo _BeautifulSoup_ processamos o conteúdo html buscando por conteúdos especificos. Ao inspecionar o código HTML verificamos em quais blocos estão as principais noticias - em geral em tags como \"section\", \"h1\"/\"h2\"/\"h3\" e \"a\" - considerando o seletor css que especifica cada bloco de interesse afim de refinar a busca e garantir que serão extraindos os trechos relevantes.\n",
    "\n",
    "Sites com boas práticas de HTML/CSS tendem a serem mais faceis de serem processados e indexados por mecanismos de buscas facilitando os usuários em encontrar seus conteúdos em pesquisas aumentando assim o engajamento em suas plataformas contribuindo para seu melhor desenvolvimento.\n",
    "\n",
    "Neste presente momento o projeto está considerando três portais de notícias que são _BBC Brasil_, _CNN Brasil_ e _G1/Globo_. \n",
    "\n",
    "Créditos e direitos reservados às referentes plataformas mencionadas.\n",
    "\n",
    "(Obs.: Conteúdo livre com fins informativos e de divulgação. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fc426",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Módulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7fe1d",
   "metadata": {},
   "source": [
    "Abaixo _import_ dos módulos que contém os recursos usados.\n",
    "\n",
    "* BeautifulSoup\n",
    "* Requests\n",
    "* re (regular expression)\n",
    "* crawlernewsg1 (acessa site e extrai lista de principais noticias na página principal do site)\n",
    "* IPython.core.display -> display, HTML (renderiza conteúdos html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad322f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from crawlernewsg1 import *\n",
    "import random\n",
    "\n",
    "# Render html content\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8683151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modelagem Portal G1\n",
    "\n",
    "Funções básicas. Especifincando \"selector css\" classe 'bastian-page'  para tags div."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando html do portal de noticia para processamento e salvando em disco.\n",
    "url = 'https://g1.globo.com'\n",
    "attr = {'class': 'bastian-page'}\n",
    "data = g1_(requests.get( url ).content, 'div', attr)\n",
    "dw = requests.get('https://g1.globo.com/').content\n",
    "with open('tmp/data', 'w') as fl:\n",
    "    fl.write( dw.decode() )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913299e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class G1:\n",
    "    def __init__(self, size_news=10, include_details = False):\n",
    "        self.size_news = size_news\n",
    "        self.include_details = include_detais\n",
    "        self.url = 'https://g1.globo.com/'\n",
    "        self.hdata = ''\n",
    "        self.htag = 'div'\n",
    "        self.attr={'class': '_b', 'id':''}\n",
    "        self.dnews = []\n",
    "        self.soup = ''\n",
    "        \n",
    "    def g1_():\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa22b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw, cwn = g1_( dw, 'div', attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dw[0]['url'])\n",
    "news1 = requests.get( dw[0]['url'] ).content\n",
    "\n",
    "#print(news1)\n",
    "soup = BeautifulSoup(news1, 'html.parser')\n",
    "\n",
    "# Extração do título da notícia.\n",
    "cwn2 = soup.find_all( 'p', {'class': 'content-text__container'} )\n",
    "cwn_title = soup.find_all( 'h1', {'class': 'content-head__title'} )\n",
    "print(\"\\n\")\n",
    "\n",
    "print( dw[0].keys() )\n",
    "#print(f\"\\n <b>{dw[0]['titulo']}</b>\\n\\n Page: {dw[0]['url']}\")\n",
    "display(HTML( f\"\"\"\\n <b>{dw[0]['titulo']}</b>\\n\\n<br><br> Page: <a href=\"{dw[0]['url']}\"> G1/Globo \"\"\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaea687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup1 = BeautifulSoup\n",
    "dw\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f163b74",
   "metadata": {},
   "source": [
    "Ao abrir link da noticia pesquisar pela tag *'p'* com atributos **class** com valor **\"content-text__container** definir o tamanho para caso extrair só parte do corpo do texto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db117b75",
   "metadata": {},
   "source": [
    "Retornando uma lista dos itens encontrados (como visto acima no código) pegamos estes itens e os concatenamos exibintido o texto no corpo da noticia. (_Como visto abaixo_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae86e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display news \n",
    "#news = '<h1 style=\"font-size: 28px; padding: 12px; text-align: center; margin: 0 auto;\">Notícia Do Dia </h1><br>'\n",
    "#news += ''.join([  str(i) for i in cwn ] )\n",
    "#display( HTML( news ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da973d9",
   "metadata": {},
   "source": [
    "Cada \"_evt\" (_css selector_ class) class css em \"bastian-page\" refere-se a uma noticia na lista central de noticias.\n",
    "Dentro de cada \"_evt\" haverá \"bastian-feed-item\" e neste o feed-post. \n",
    "\n",
    "**feed-post-body** _contêm_  ( 'feed-post-link', 'feed-post-body-title', 'feed-post-body-resumo')\n",
    "\n",
    "**bastian-feed-item** _contem_ um feed-post-body referindo-se a cada item (noticia)\n",
    "\n",
    "\n",
    "Para link da noticia (quando acessando a noticia)\n",
    "\n",
    "**content-head__title** em tag 'h1' (Título da noticia)\n",
    "\n",
    "**content-head__subtitle** em tag 'h2' (subtitulo/resumo da noticia)\n",
    "\n",
    "**content-text__container** corpo do texto da noticia css-selector, tag 'p' (pegar só a primeira referente ao primeiro paragrafo da noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daeff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_news = '\\n '.join([i.text for i in cwn ])\n",
    "#print(text_news)\n",
    "#help( cwn[0] )\n",
    "#dir(cwn[0])\n",
    "\n",
    "#dir(cwn[0])\n",
    "#print('bastian-feed-item', cwn[0].contents[0].select( \".bastian-feed-item\") )\n",
    "\n",
    "nw = cwn[0].contents[0].select('._evt')\n",
    "print( nw[3].contents )\n",
    "nw2 = cwn[0].contents[0].select('.bastian-feed-item')\n",
    "print('Número de noticias %s'%len(nw2) )\n",
    "\n",
    "\n",
    "#( nw2[0].select('.feed-post-body-title')[0].text, nw2[0].select('.feed-post-body-resumo' )[0].text , nw2[0].select('.feed-post-link')[0]['href'] )\n",
    "\n",
    "#l = [ i.text for i in  [ j.select('.feed-post') for j in cwn[0].contents[0].select('.bastian-feed-item') ] ]\n",
    "#l[0]\n",
    "#nw2[1].select('.feed-post-body-title')[0].text\n",
    "#nw2[1].select('.feed-post-body-resumo' )[0].text\n",
    "#nw2[1].select('.feed-post-link')\n",
    "nws = [  {'titulo': i.select('.feed-post-body-title'), \n",
    "'resumo': i.select('.feed-post-body-resumo' ) ,\n",
    "'url': i.select('.feed-post-link') } for i in nw2 ]\n",
    "\n",
    "#nws\n",
    "\n",
    "url_key = 'url'\n",
    "href_key = 'href'\n",
    "template = f\"\"\"\n",
    "< div style=\"padding: 2px; border: 1px solid gray; background: whitesmoke;\"> \n",
    "{url} \n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# '<h3 style=\"padding: 4px;\">'+ k['titulo'][0].text + f'<a href=\"\" style=\"padding: 2px;\" >{k[\"url\"][0][\"href\"]}' for k in nws  \n",
    "#p = ''.join([ \"<h3>\" + k['titulo'][0].text + \"</h3>\" + \"<br>\" + [ str( k['resumo'][0].text ) if ( len(k['resumo']) !=  0 ) else \"\" ][0] + '<br>' + k['url'][0]['href'] for  k in nws ])\n",
    "p = ' '.join( \n",
    "    [ \n",
    "       f'<h3 style=\"padding: 2px;\"> {k[\"titulo\"][0].text}</h3>' + f'<a href=\"{k[url_key][0][href_key]}\" style=\"padding: 1px; margin: 0;\" >Leia mais</a>' for k in nws  \n",
    "       \n",
    "    ]\n",
    ")\n",
    "\n",
    "#print( p )\n",
    "display(( HTML( p )) )\n",
    "\n",
    "#[ 1 if 2 > 3 else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news2 = '<h1 style=\"padding: 12px;\">Notícias</h1>'\n",
    "news2 += '<br><br>'.join( [ '<br>'.join( [ str( i['titulo'] ) , str( i[ 'url' ]  ) ] ) for i in dw ] )\n",
    "display( HTML( news2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyespeak\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32396b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nws_data = [\n",
    "     requests.get( i['url'][0]['href'])  for i in nws \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de noticias capturadas: {len(nws_data)}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup(nws_data.content, 'html.parser').find()[0]\n",
    "#BeautifulSoup(nws_data.content, 'html.parser').find()[0]\n",
    "#BeautifulSoup(nws_data.content, 'html.parser').find()[0]\n",
    "# g1_(i.content, 'h1', {'class': 'content-head__title'} )[0], g1_( i.content, 'h2', {'class': 'content-head__subtitle' } )[0], g1_(i.content, 'p', {'class':'content-text__container'})[0][0]  ] for i in nws_data \n",
    "nws_data_ = []\n",
    "g1aux = None \n",
    "\n",
    "for i in nws_data[:3]:\n",
    "    try:\n",
    "\n",
    "        nws_data_.append( \n",
    "            [ \n",
    "                BeautifulSoup(i.content, 'html.parser').find('h1', class_='content-head__title' ).text,\n",
    "                BeautifulSoup(i.content, 'html.parser').find('h2', class_='content-head__subtitle').text,\n",
    "                BeautifulSoup(i.content, 'html.parser').find('p', class_='content-text__container').text\n",
    "            ]\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#print(nws_data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nws_data_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = 'Olá. Bem vindo e bem vinda ao nosso noticiário diário. Eu sou Ani Fátima Liu e apresentarei as principais noticias. \\n'\n",
    "s_interv = 'Agora vamos a nossa próxima notícia.'\n",
    "\n",
    "#for i in nws_data_[0]:\n",
    "#    s += i\n",
    "\n",
    "for i in nws_data_[:3]:\n",
    "    for j in i:\n",
    "        s += j\n",
    "    s += s_interv+'\\n'\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bf20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyespeak.speech(s, '120', 'noticia_dia_full.wav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b27fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5cc259",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CNN Crawler de Noticias do Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca259fc-90c1-4652-a537-0147ef73aa09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d731b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_data = requests.get('https://www.cnnbrasil.com.br/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06682a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_soup = BeautifulSoup(cnn_data.content, 'html.parser')\n",
    "cnn_nw_data = cnn_soup.find_all('section')\n",
    "cnn_nw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7052da",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cnn_nw_data[0].find('a')\n",
    "#dir(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa59afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_list_news = []\n",
    "aux = None \n",
    "for news in cnn_nw_data:\n",
    "    aux = news.find('a')\n",
    "    \n",
    "    \n",
    "    try :\n",
    "        \n",
    "        aux = aux.attrs\n",
    "        cnn_list_news.extend( [ { 'title': aux['title'], 'href': aux['href'] } ] ) \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(cnn_list_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2be6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_list_news_ma = None\n",
    "for i in cnn_list_news:\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\n{i['title']} \\n{i['href']}\\n\\n\" ) \n",
    "    except:\n",
    "        pass \n",
    "    #keys = i.keys()\n",
    "    #print(keys)   \n",
    "    \n",
    "\n",
    "    #print( f'\\t\\n\\n{out}') \n",
    "    #out = '' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18478fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81147e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cnn_list_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdb6c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# BBC Brasil "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05e698",
   "metadata": {},
   "source": [
    "Crawler das notícias do portal do site BBC Brasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bbc = 'https://www.bbc.com/portuguese'\n",
    "url_bbc_base = 'https://www.bbc.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfcf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_data = requests.get(url_bbc)\n",
    "bbc_soup = BeautifulSoup(bbc_data.content, 'html.parser')\n",
    "bbc_sections =  bbc_soup.find_all('section' , class_= 'bbc-iinl4t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff387772",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_lists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e14fbd",
   "metadata": {},
   "source": [
    "``` python\n",
    "url_bbc_base+bbc_sections[0].select('a')[0]['href']\n",
    "```\n",
    "\n",
    "Saída 'https://www.bbc.com/portuguese/brasil-63507138'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0594c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_sections[0].select('a')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for news in bbc_sections:\n",
    "    bbc_news_lists.extend( [ { 'title': i.text, 'url': i['href'] } for i in news.select('a') ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73480045",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_lists = []\n",
    "aux = None \n",
    "\n",
    "for section_news in bbc_sections:\n",
    "    for news in section_news.select( 'a' ):\n",
    "        if news['href'].find('topic') != -1:\n",
    "            pass\n",
    "        else :\n",
    "            if news['href'].find('https') != -1:\n",
    "                bbc_news_lists.extend( [ { 'title': news.text, 'href': news['href'] } ] )\n",
    "            else:\n",
    "                bbc_news_lists.extend( [ { 'title': news.text, 'href': url_bbc_base+news['href'] } ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21212bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de notícias: {len(bbc_news_lists)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(bbc_news_lists, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a68bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url_bbc_base+'/portuguese/topics/cz74k71p8ynt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a107ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bbc_news.txt', 'w') as fl:\n",
    "    for i in bbc_news_lists:\n",
    "        fl.write(i['title'] +'\\n' + i['href'] +'\\n\\n')\n",
    "    fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db2d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e4d2bbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Montando Lista de Notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_news = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ea054",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = []\n",
    "\n",
    "news_list.extend( [ {'title': random.choices( [ (news['titulo'], news['url']) for news in dw ] , k = 2 ), 'source': 'G1/Globo' } ] )\n",
    "\n",
    "news_list.extend( [ {'title': random.choices( [ (news['title'], news['href']) for news in cnn_list_news ] , k = 2 ), 'source': 'CNN Brasil' } ] )\n",
    "\n",
    "news_list.extend( [ {'title': random.choices( [ (news['title'], news['href']) for news in bbc_news_lists ] , k = 2 ), 'source': 'BBC Brasil' } ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974176ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in news_list:\n",
    "    for j in i['title']:\n",
    "        print(f\"{j[0]}. \\n{j[1]}\\n\")\n",
    "    \n",
    "    print(f\"Fonte: {i['source']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = j = None\n",
    "\n",
    "for i in news_list:\n",
    "    for j in i['title']:\n",
    "        print(f'{j[0]}.')\n",
    "    print(f'Fonte: {i[\"source\"] }\\n\\n ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ca847-a7d0-4941-bfc7-14c8b2123ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = j = None\n",
    "\n",
    "print(f\"Olá bem vindo ao Diário de Notícias Dimensão Alfa. Estas são as principais manchetes do dia.\\n\")\n",
    "for i in news_list:\n",
    "    print(f'Portal de Notícias {i[\"source\"] }\\n ' )\n",
    "    for j in i['title']:\n",
    "        print(f'{j[0]}.')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1879811-0f8b-4150-86a7-606389a58301",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sobre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c3c3a-34bd-4081-a3de-4d172f80eb07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dimensão Alfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93927b53-1f5b-4f94-abed-cf9e6f99fc99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Dimensão Alfa é uma página no formato de revista eletrônica/digital que trás conhecimento e notícias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922c82b-a271-4e7c-b6f7-a1420b69b13f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669e98a-92e1-4d73-b518-163002feab8b",
   "metadata": {},
   "source": [
    "O presente projeto tem sido usado com fins de divulgação e facilitação de acesso a noticias e conhecimento em comunhão com objetivo da plataforma/página Dimensão Alfa. \n",
    "Conteúdos de terceiros são de responsabilidades dos mesmos bem como seus direitos autorais.\n",
    "\n",
    "O projeto encontra-se em desenvolvimento, inicialmente fôra batizado de Ani Fátima Liu, e estará passando por alterações estando de inicio disponibilizado em formato \"_jupyter notebook_\" podendo servir como _case_ de estudo para os que se interessam por \"web scrap\" (raspagem de dados).\n",
    "\n",
    "Tecnologias foram usadas para gerar vídeo de noticias diária para página [Dimensão Alfa no facebook](https://www.facebook.com) e [Youtube](https://www.youtube.com/@dimensaoalfa); foi usada as seguintes tecnologias:\n",
    "\n",
    "* [Editor de códigos VSCode](https://code.visualstudio.com/)\n",
    "* [Python (linguagem de programação)](https://www.python.org/)\n",
    "* [Ambiente JupyterLab](https://jupyter.org/)\n",
    "* [Biblioteca \"Requests\"](https://requests.readthedocs.io/en/latest/)\n",
    "* [Biblioteca \"BeautifulSoup\"](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [Serviço de Sintese de Voz Microsoft/Azure](https://speech.microsoft.com)\n",
    "\n",
    "\n",
    "Peço e agradeço a compreensão e apoio de todos. \n",
    "\n",
    "Para contribuições, dúvidas, sugestões visitem nossas páginas no [Facebook](https://www.facebook.com/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6698c-a66b-47a8-aacc-444904c32d39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sugestões de Conteúdo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ff71a-b892-48d4-a647-227402170487",
   "metadata": {
    "tags": []
   },
   "source": [
    "Deixamos abaixo algumas sugestões de conteúdos e canais com recursos para estudos e pesquisa que podem ser uteis para quem se interessa por tecnologia, programação de computadores, matemática, ciências de dados e inteligência artificial.\n",
    "\n",
    "* [Programação Dinâmica](https://www.youtube.com/c/Programa%C3%A7%C3%A3oDin%C3%A2mica)\n",
    "* [Toda Matemática](https://www.youtube.com/c/GustavoViegascurso)\n",
    "* [Matemática Universitária](https://www.youtube.com/c/Matem%C3%A1ticaUniversit%C3%A1riaProfRenan)\n",
    "* [Reflexões Matemáticas](https://www.youtube.com/c/Reflex%C3%B5esMatem%C3%A1ticasDrDilbertoJ%C3%BAnior)\n",
    "* [Programação Descomplicada](https://www.youtube.com/user/progdescomplicada)\n",
    "* [Univesp](https://www.youtube.com/user/univesptv)\n",
    "* [USP no Youtube](https://www.youtube.com/c/CanalUSP)\n",
    "* [IME/USP](https://www.ime.usp.br/)\n",
    "* [IMPA](https://www.youtube.com/c/impabr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d7325-7366-4924-8c94-fbefbeefdf51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1176b-3805-4997-aca5-9d581b1bafb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "* [Dimensão Alfa](https://www.dimensaoalfa.com.br)\n",
    "* [Facebook](https://www.facebook.com/dimensaoalfa)\n",
    "* [Youtube](https://www.youtube.com/@dimensaoalfa)\n",
    "* [WSRicardo](https://wsricardo.blogspot.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af3df7-db38-4951-a18d-8e93b8f71d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
