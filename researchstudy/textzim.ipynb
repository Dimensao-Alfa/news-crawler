{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b931201a-4805-4f0c-964f-377579a901c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libzim.reader import Archive\n",
    "from libzim.search import Query, Searcher\n",
    "from libzim.suggestion import SuggestionSearcher\n",
    "\n",
    "# Arquivo com conteúdo da wikipedia para ser visualizado offline.\n",
    "# Os dados obtidos serão usado para treinamento do chatbot.\n",
    "zim = Archive(\"test.zim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "98ec42f1-3de2-4d78-977e-fab056c4f21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archive(filename=test.zim)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e0cd4724-54b0-464b-a0f2-1c2ccd62b068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098416"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zim.article_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f9bf7acd-103b-4f11-8998-36655656062a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A/Wikipédia:Offline'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zim.main_entry.get_item().path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f538d238-178c-4e63-8789-84f092e7a7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_get_entry_by_id',\n",
       " 'all_entry_count',\n",
       " 'article_count',\n",
       " 'check',\n",
       " 'checksum',\n",
       " 'entry_count',\n",
       " 'filename',\n",
       " 'filesize',\n",
       " 'get_entry_by_path',\n",
       " 'get_entry_by_title',\n",
       " 'get_illustration_item',\n",
       " 'get_illustration_sizes',\n",
       " 'get_metadata',\n",
       " 'get_metadata_item',\n",
       " 'has_checksum',\n",
       " 'has_entry_by_path',\n",
       " 'has_entry_by_title',\n",
       " 'has_fulltext_index',\n",
       " 'has_illustration',\n",
       " 'has_main_entry',\n",
       " 'has_new_namespace_scheme',\n",
       " 'has_title_index',\n",
       " 'is_multipart',\n",
       " 'main_entry',\n",
       " 'media_count',\n",
       " 'metadata_keys',\n",
       " 'uuid']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(zim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bd627d99-464c-4820-9c51-42766510f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '_get_entry_by_id', 'all_entry_count', 'article_count', 'check', 'checksum', 'entry_count', 'filename', 'filesize', 'get_entry_by_path', 'get_entry_by_title', 'get_illustration_item', 'get_illustration_sizes', 'get_metadata', 'get_metadata_item', 'has_checksum', 'has_entry_by_path', 'has_entry_by_title', 'has_fulltext_index', 'has_illustration', 'has_main_entry', 'has_new_namespace_scheme', 'has_title_index', 'is_multipart', 'main_entry', 'media_count', 'metadata_keys', 'uuid']\n",
      "A/Wikipédia:Offline\n",
      "Entry Wikipédia:Offline at A/Wikipédia:Offline is 17012b.\n"
     ]
    }
   ],
   "source": [
    "#print(f\"Main entry is at {zim.main_entry.get_item().path}\")\n",
    "#entry = zim.get_entry_by_path(\"A/Wikipédia\")\n",
    "# ENtradas no arquivo \n",
    "entry = zim.get_entry_by_path(zim.main_entry.path)\n",
    "print(dir(zim))\n",
    "print(zim.main_entry.path)\n",
    "print(f\"Entry {entry.title} at {entry.path} is {entry.get_item().size}b.\")\n",
    "#print(bytes(entry.get_item().content).decode(\"UTF-8\"))\n",
    "\n",
    "# searching using full-text index\n",
    "#search_string = \"computação\"\n",
    "#query = Query().set_query(search_string)\n",
    "#searcher = Searcher(zim)\n",
    "#search = searcher.search(query)\n",
    "#search_count = search.getEstimatedMatches()\n",
    "#print(f\"there are {search_count} matches for {search_string}\")\n",
    "#print(list(search.getResults(0, search_count) ) )\n",
    "\n",
    "# accessing suggestions\n",
    "#search_string = \"kiwix\"\n",
    "#suggestion_searcher = SuggestionSearcher(zim)\n",
    "#suggestion = suggestion_searcher.suggest(search_string)\n",
    "#suggestion_count = suggestion.getEstimatedMatches()\n",
    "#print(f\"there are {suggestion_count} matches for {search_string}\")\n",
    "#print(list(suggestion.getResults(0, suggestion_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "343609ed-6930-4a3c-890f-cdd6cd4b6053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A/Computador_pessoal', 'A/Computador_quântico']\n"
     ]
    }
   ],
   "source": [
    "print(list( search.getResults(0, 2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "630fee1f-e58a-441f-804d-d4923752ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libzim.reader\n",
    "import libzim\n",
    "\n",
    "\n",
    "#help(libzim.reader)\n",
    "#[zim.get_entry_by_title(i) for i in entry ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "283c3ee2-67e4-45b0-9494-d4cfe1b54e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4229322076.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_23901/4229322076.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    breve sumário usando o artigo selecionado e retorna-lo para o usuário.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# Importar pandas criar uma tabela com tokens (palavras) no texto e conta-las\n",
    "# palavras com maior ocorrências defini-las como 'key words'\n",
    "# criar um conjunto com campos titulo do artigo, corpo do artigo, palavras chaves\n",
    "# Em um chat ao identificar palavras chaves (keywords) inseridas por usuario\n",
    "# buscar no conjunto dos artigos e através de tácnicas de cadeias de markov gerar um\n",
    " breve sumário usando o artigo selecionado e retorna-lo para o usuário.\n",
    "\n",
    "#print( bytes( zim.get_entry_by_path( list( search.getResults(0, 2) )[0] ).get_item().content).decode('UTF-8' ) )\n",
    "webcont = bytes( zim.get_entry_by_path( list( search.getResults(0, 2) )[1] ).get_item().content).decode('UTF-8' )\n",
    "\n",
    "soupwiki = BeautifulSoup(webcont, 'html.parser')\n",
    "print(  soupwiki.get_text().replace('\\n', ' ') ) \n",
    "#soupwiki.get_text().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bcb43-e1be-4d92-b8bd-a52659089596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e3d07-023c-4737-93a4-522886a5c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordspec = ('o', 'a', 'A', 'e', 'E','como', 'este', 'estes', 'estas', 'Estes', 'Estas', 'esse', 'esses', 'Esses', 'Esse', 'dos', 'Dos', 'Das', 'das', 'Como','em', 'mas', 'mais', 'com','algum', 'num', 'por', 'desse', 'desses', 'Desse', 'Desses', 'Dessa', 'dessa', 'Dessas', 'Dessas', 'Num', 'Numa', 'numa', 'alguns', 'Algum', 'Alguns', 'Com', 'tal', 'tais', 'no', 'na', 'Na', 'No', 'O', 'ao', 'para', 'um', 'uma', 'Uma', 'Um',  'pra', '.', ',', '?', ':', ';', '/', '(', ')', '\"', \"'\", '\\\\' ,'de', 'da', 'do', 'que', 'lhe', 'aquele', 'aquela')\n",
    "soupwtext =  soupwiki.get_text()\n",
    "# Remove ponctuations signals.\n",
    "for i in [',', '.', '?', '!', '-' , ')', '(' ]:\n",
    "    soupwtext = soupwtext.replace(i, ' ')\n",
    "\n",
    "# Removendo preposições, artigos e pronomes da lingua portuguesa.\n",
    "c = dict( Counter( [  str.lower(i) if not ( i in wordspec or len(i) < 2 ) else '-1' for i in soupwtext.replace('\\n', ' ').split()  ] )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb3a69-e3d9-455d-97fb-86a3beaf4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A chave '-1' no dicionário representa números de items removidos entre os que estão em wordspec ou são sinais de pontuação.\n",
    "c.pop('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535b897-85be-4e29-9d8a-762c126869c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e454ab9-77bf-4fed-aca5-987e0d896c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "# Gerando dicionário contendo as três palavras que mais ocorrem no texto\n",
    "dn = c.copy()\n",
    "keywords = {}\n",
    "for i in [1, 2, 3]:\n",
    "    elem = max(dn.items(), key=operator.itemgetter(1))\n",
    "    keywords[elem[0]] = elem[1] \n",
    "    dn.pop(elem[0])\n",
    "    \n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ee234-4929-467a-adba-753c7c7a8a5f",
   "metadata": {},
   "source": [
    "O mesmo processo acima pode ser aplicada a texto inserido pelo usuário de modo que bot extraia as palavras chaves e busque elas nas listas de artigos afim de retornar\n",
    "a informação encontrada para o que usuário digitou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc20af-829a-47bd-adaa-d47c9860f2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
